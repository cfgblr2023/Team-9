{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwpAvbwMVYLn",
        "outputId": "ddd08d03-51ae-4d0c-850e-6811c66340f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/Walking ./"
      ],
      "metadata": {
        "id": "YFbbQktzYbML"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDGuaD2tVPZW",
        "outputId": "63853ac5-9225-492e-b134-ec1b0b4c6994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 63s 1s/step - loss: 2.1357 - accuracy: 0.3542 - val_loss: 2.7738 - val_accuracy: 0.3000\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 14s 958ms/step - loss: 0.8047 - accuracy: 0.7958 - val_loss: 4.6513 - val_accuracy: 0.2333\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 15s 994ms/step - loss: 0.3458 - accuracy: 0.9042 - val_loss: 5.3461 - val_accuracy: 0.2250\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 15s 1s/step - loss: 0.1651 - accuracy: 0.9521 - val_loss: 6.6163 - val_accuracy: 0.2250\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.0945 - accuracy: 0.9792 - val_loss: 6.2268 - val_accuracy: 0.2750\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 17s 1s/step - loss: 0.0686 - accuracy: 0.9896 - val_loss: 5.1073 - val_accuracy: 0.2500\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.0320 - accuracy: 0.9979 - val_loss: 6.8615 - val_accuracy: 0.2000\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 15s 1s/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 6.4180 - val_accuracy: 0.2583\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 15s 1s/step - loss: 0.0759 - accuracy: 0.9771 - val_loss: 6.0475 - val_accuracy: 0.2083\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.0755 - accuracy: 0.9833 - val_loss: 3.3559 - val_accuracy: 0.2250\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load labels\n",
        "df = pd.read_csv('/content/drive/MyDrive/Issues_Collected_category and issue - Issues consolidatd.csv')\n",
        "labels = df['Issue type'].values\n",
        "photos = df['Photo'].values\n",
        "\n",
        "# Convert labels to numerical values\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "# Preprocess images\n",
        "image_list = []\n",
        "for photo in photos:\n",
        "    image = load_img('/content/Walking/' + photo, target_size=(299, 299))\n",
        "    image = img_to_array(image)\n",
        "    image = preprocess_input(image)\n",
        "    image_list.append(image)\n",
        "images = np.array(image_list)\n",
        "\n",
        "# Define the model\n",
        "base_model = Xception(include_top=False, weights='imagenet', input_shape=(299, 299, 3), pooling='avg')\n",
        "output = Dense(len(le.classes_), activation='softmax')(base_model.output)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(images, labels, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Save the model\n",
        "model.save('xception_model.h5')\n"
      ]
    }
  ]
}